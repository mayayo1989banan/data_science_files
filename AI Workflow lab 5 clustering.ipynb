{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# CASE STUDY - Unsupervised Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "#from imbalanced-learn import imblearn\n",
    "import imblearn.pipeline as pl\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE\n",
    "    \n",
    "    \n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  \n",
    "## Outline\n",
    "\n",
    "1. Create a churn prediction baseline model\n",
    "2. Use clustering as part of your prediction pipeline\n",
    "3. Run and experiment to see if re-sampling techniques improve your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>subscriber_type</th>\n",
       "      <th>num_streams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>united_states</td>\n",
       "      <td>21</td>\n",
       "      <td>aavail_premium</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>singapore</td>\n",
       "      <td>30</td>\n",
       "      <td>aavail_unlimited</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>united_states</td>\n",
       "      <td>21</td>\n",
       "      <td>aavail_premium</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>united_states</td>\n",
       "      <td>20</td>\n",
       "      <td>aavail_basic</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singapore</td>\n",
       "      <td>21</td>\n",
       "      <td>aavail_premium</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  age   subscriber_type  num_streams\n",
       "0  united_states   21    aavail_premium           23\n",
       "1      singapore   30  aavail_unlimited           12\n",
       "2  united_states   21    aavail_premium           22\n",
       "3  united_states   20      aavail_basic           19\n",
       "4      singapore   21    aavail_premium           23"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = os.path.join(\"D:\\\\data_science\\\\Clustering-Case-Study-Local\",\"data\")\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, r\"aavail-target.csv\"))\n",
    "\n",
    "## pull out the target and remove uneeded columns\n",
    "_y = df.pop('is_subscriber')\n",
    "y = np.zeros(_y.size)\n",
    "y[_y==0] = 1 \n",
    "df.drop(columns=['customer_id', 'customer_name'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using the train_test_split() function, create a stratified train test split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df,pd.Series(y), test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "\n",
    "Create a baseline model.  We are going to test whether clustering followed by a model improves the results.  Then, we will test whether re-sampling techniques provide improvements.  Use a pipeline or another method, but create a baseline model given the data. Here is the ColumnTransformer we have used before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing pipeline\n",
    "numeric_features = ['age', 'num_streams']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['country', 'subscriber_type']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encod', OrdinalEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score 0.626\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE (Replace the #<> symbols with your code)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from numpy.random import RandomState as rs\n",
    "\n",
    "np.random.seed(13)\n",
    "\n",
    "\n",
    "# Create an instance of a binary classifier. \n",
    "clf = SGDClassifier(max_iter=1000, learning_rate = 'constant', eta0 = 0.1, alpha = 0, loss = 'log')\n",
    "\n",
    "\n",
    "# Create a Pipeline that binds the preprocessing transformer and the classifier estimator.\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),('classifier', clf)])\n",
    "\n",
    "\n",
    "# Fit the pipeline to the training data.\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# predict the dependent variable of the test set.\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "#pr = pipe.predict_proba(X_test)\n",
    "#pr\n",
    "\n",
    "# Print the f1_score of the prediction.\n",
    "print(\"f1_score\", round(f1_score(y_test, y_pred, average='binary'), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans & GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 4)\n",
      "(800, 5)\n",
      "(800, 4)\n",
      "(800, 8)\n"
     ]
    }
   ],
   "source": [
    "class KmeansTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=4):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.km = KMeans(n_clusters=self.n_clusters, n_init=20)\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        labels = self.km.predict(X)\n",
    "        return np.hstack((X, labels.reshape(-1, 1)))\n",
    "\n",
    "    def fit(self, X, y=None, *_):\n",
    "        self.km.fit(X)\n",
    "        labels = self.km.predict(X)\n",
    "        self.silhouette_score = round(silhouette_score(X, labels, metric='mahalanobis'), 3)\n",
    "        return self\n",
    "\n",
    "class GmmTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=4):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gmm = BayesianGaussianMixture(n_components=self.n_clusters, covariance_type='full',\n",
    "                                           max_iter=500, n_init=10, warm_start=True)        \n",
    "    def transform(self, X,*_):\n",
    "        probs = self.gmm.predict_proba(X) + np.finfo(float).eps\n",
    "        return np.hstack((X, probs))\n",
    "        \n",
    "    def fit(self, X, y=None, *_):\n",
    "        self.gmm.fit(X)\n",
    "        labels = self.gmm.predict(X)\n",
    "        self.silhouette_score = round(silhouette_score(X, labels, metric='mahalanobis'), 3)\n",
    "        return self\n",
    "    \n",
    "\n",
    "    \n",
    "## example for kmeans\n",
    "preprocessor.fit(X_train)\n",
    "X_train_pre = preprocessor.transform(X_train)    \n",
    "kt = KmeansTransformer(4)\n",
    "kt.fit(X_train_pre)\n",
    "X_train_kmeans = kt.transform(X_train_pre)\n",
    "print(X_train_pre.shape)\n",
    "print(X_train_kmeans.shape)   \n",
    "    \n",
    "## example for GMM  \n",
    "preprocessor.fit(X_train)\n",
    "X_train_pre = preprocessor.transform(X_train)    \n",
    "gt = GmmTransformer(4)\n",
    "gt.fit(X_train_pre)\n",
    "X_train_gmm = gt.transform(X_train_pre)\n",
    "print(X_train_pre.shape)  \n",
    "print(X_train_gmm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kmeans</th>\n",
       "      <th>gmm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_clusters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.563</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.596</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.514</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.639</td>\n",
       "      <td>0.574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            kmeans    gmm\n",
       "n_clusters               \n",
       "3            0.563  0.579\n",
       "4            0.490  0.559\n",
       "5            0.596  0.500\n",
       "6            0.514  0.557\n",
       "7            0.639  0.574"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def run_clustering_pipeline(umodel):\n",
    "    \"\"\"\n",
    "    This function evaluates different Pipelines comprised of the preprocessing transfomer,\n",
    "    a clustering transformer and a classifier estimator.\n",
    "    INPUT : The name of the clustering transformer : 'gmm' or 'kmeans'\n",
    "    OUTPUT : The list of f1_scores of the pipeline on the test set for the different number of clusters\n",
    "    \"\"\"\n",
    "    fscores= [] # this list will store the f1_score of the different models that we will train\n",
    "    for n_clusters in np.arange(3, 8):\n",
    "\n",
    "        # Create an instance of a binary classifier (The same as the one you trained in the previous question)\n",
    "        clf = SGDClassifier(max_iter=1000, learning_rate = 'constant', eta0 = 0.1, alpha = 0, loss = 'log')\n",
    "        \n",
    "        if umodel == 'gmm':\n",
    "            # Create an instance of the Gmm transformer with n_clusters clusters\n",
    "            cluster =   GmmTransformer(n_clusters)\n",
    "        elif umodel == 'kmeans':\n",
    "            # Create an instance of the Kmean transformer with n_clusters clusters\n",
    "            cluster =  KmeansTransformer(n_clusters)\n",
    "        else:\n",
    "            raise Exception(\"invalid unsupervised learning model\")\n",
    "        \n",
    "        # Create a Pipeline that binds the preprocessing transformer, the clustering transformer and the classifier estimator\n",
    "        pipe = pipe = Pipeline(steps = [\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('clustering', cluster),\n",
    "                     ('classifier', clf)\n",
    "                    ])\n",
    "    \n",
    "        # Fit the pipeline on training set\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict the test set\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # Compute the f1 score and add this score to the fscores list.\n",
    "        score = round(f1_score(y_test, y_pred, average='binary'), 3)\n",
    "        fscores.append(score)\n",
    "        \n",
    "    return fscores\n",
    "\n",
    "## run the different iteration of the model\n",
    "cp_results = {}\n",
    "cp_results['kmeans'] = run_clustering_pipeline('kmeans')\n",
    "cp_results['gmm'] = run_clustering_pipeline('gmm')\n",
    "\n",
    "## display table of results\n",
    "df_cp = pd.DataFrame(cp_results)\n",
    "df_cp[\"n_clusters\"] = [str(i) for i in np.arange(3,8)]\n",
    "df_cp.set_index(\"n_clusters\", inplace=True)\n",
    "df_cp.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add SMOTE\n",
    "\n",
    "Run an experiment to see if you can you improve on your workflow with the addition of re-sampling techniques? For instance, you can copy the structure of the function created in the previous question and add a re-sampling transformer to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kmeans</th>\n",
       "      <th>gmm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_clusters</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.571</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.626</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.569</td>\n",
       "      <td>0.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.621</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            kmeans    gmm\n",
       "n_clusters               \n",
       "3            0.571  0.540\n",
       "4            0.626  0.626\n",
       "5            0.569  0.615\n",
       "6            0.621  0.626\n",
       "7            0.580  0.603"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def run_clustering_pipeline(umodel):\n",
    "    \"\"\"\n",
    "    This function evaluates different Pipelines constituated of the preprocessing transfomer,\n",
    "    a clustering transformer, a re-sampling transformer and a classifier estimator.\n",
    "    INPUT : The name of the clustering transformer : 'gmm' or 'kmeans'\n",
    "    OUTPUT : The list of f1_scores of the pipeline on the test set for the different number of clusters.\n",
    "    \"\"\"\n",
    "    fscores= [] # this list will store the f1_score of the different models that we will train\n",
    "    for n_clusters in np.arange(3, 8):\n",
    "\n",
    "        # Create an instance of a binary classifier (The same as the one you trained in the previous question)\n",
    "        clf = SGDClassifier(max_iter=1000, learning_rate = 'constant', eta0 = 0.1, alpha = 0, loss = 'log')\n",
    "        \n",
    "        if umodel == 'gmm':\n",
    "            # Create an instance of the Gmm transformer with n_clusters clusters\n",
    "            cluster =   GmmTransformer(n_clusters)\n",
    "        elif umodel == 'kmeans':\n",
    "            # Create an instance of the Kmean transformer with n_clusters clusters\n",
    "            cluster =  KmeansTransformer(n_clusters)\n",
    "        else:\n",
    "            raise Exception(\"invalid unsupervised learning model\")\n",
    "        \n",
    "        smote = SMOTE(random_state=42)\n",
    "        # Create a Pipeline that binds the preprocessing transformer, the clustering transformer and the classifier estimator\n",
    "        pipe = pl.Pipeline(steps = [\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('clustering', cluster),\n",
    "                    ('smote', smote),\n",
    "                     ('classifier', clf) ])\n",
    "    \n",
    "        # Fit the pipeline on training set\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict the test set\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # Compute the f1 score and add this score to the fscores list.\n",
    "        score = round(f1_score(y_test, y_pred, average='binary'), 3)\n",
    "        fscores.append(score)\n",
    "      \n",
    "    return(fscores)\n",
    "\n",
    "## run the different iteration of the model\n",
    "cp_results = {}\n",
    "cp_results['kmeans'] = run_clustering_pipeline('kmeans')\n",
    "cp_results['gmm'] = run_clustering_pipeline('gmm')\n",
    "\n",
    "\n",
    "## display table of results\n",
    "df_cp = pd.DataFrame(cp_results)\n",
    "df_cp[\"n_clusters\"] = [str(i) for i in np.arange(3,8)]\n",
    "df_cp.set_index(\"n_clusters\",inplace=True)\n",
    "df_cp.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
